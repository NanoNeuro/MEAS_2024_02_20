{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si  # import core only\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.curation as scur\n",
    "import spikeinterface.widgets as sw\n",
    "from spikeinterface.sortingcomponents.peak_detection import detect_peaks\n",
    "from spikeinterface.sortingcomponents.peak_localization import localize_peaks\n",
    "\n",
    "from typing import Tuple, List\n",
    "from probeinterface import Probe\n",
    "\n",
    "def load_recording_from_raw(root: str, sample_base: str, well: Tuple[int, int], time_samplings_to_mask: List[Tuple[float, float]]):\n",
    "\n",
    "    traces_list = []\n",
    "    channel_ids = []\n",
    "\n",
    "    df = pd.read_csv(f'{root}/{sample_base}/{sample_base}.info', index_col=0, names=['index', 'value'], sep='\\t')\n",
    "    sampling_frequency = df.loc['SamplingFrequency', 'value']\n",
    "    voltage_scale = np.abs(df.loc['VoltageScale', 'value'])\n",
    "\n",
    "    # We choose 10 here because in 64-electrode MEAs the range would be up to 9. \n",
    "    # Since the time required for the non-existing electrodes is small, we don't mine using a larger number.\n",
    "    for Erow in range(1,10):  \n",
    "        for Ecol in range(1,10):\n",
    "            filename = f'{root}/{sample_base}/{well[0]}-{well[1]}-{Erow}-{Ecol}_voltageRaw'\n",
    "            is_txt, is_gzip = os.path.exists(f'{filename}.txt'), os.path.exists(f'{filename}.txt.gz') \n",
    "\n",
    "            if is_txt or is_gzip:\n",
    "                channel_ids.append(f'{Erow}-{Ecol}')\n",
    "                \n",
    "                if is_txt:\n",
    "                    list_voltages = np.loadtxt(f'{filename}.txt')\n",
    "                elif is_gzip:\n",
    "                    list_voltages = np.loadtxt(f'{filename}.txt.gz')\n",
    "\n",
    "                traces_list.append(list_voltages)\n",
    "            \n",
    "\n",
    "    trace_array = np.asarray(traces_list).transpose() / voltage_scale\n",
    "\n",
    "    for time_sampling in time_samplings_to_mask:\n",
    "        t0 = int(time_sampling[0] * sampling_frequency)\n",
    "        tf = int(time_sampling[1] * sampling_frequency)\n",
    "        trace_array[t0:tf, :] = 0\n",
    "\n",
    "    sample_recording = si.NumpyRecording(\n",
    "        traces_list=[trace_array],\n",
    "        sampling_frequency=sampling_frequency,\n",
    "        channel_ids=np.asarray(channel_ids)\n",
    "    )\n",
    "\n",
    "    sample_recording.set_property('group', [0] * len(channel_ids))\n",
    "    sample_recording.is_dumpable = True  # This is necessary for some options later, like spike sorting\n",
    "\n",
    "    return sample_recording\n",
    "\n",
    "\n",
    "def load_probe_recording(recording: si.NumpyRecording, type_MEAS: int, ):\n",
    "    dist_multiplier = 350 if type_MEAS == 16 else 300\n",
    "    circle_radius = 50\n",
    "\n",
    "    channel_ids = recording.get_channel_ids()\n",
    "\n",
    "    positions = np.zeros((len(channel_ids), 2), dtype=float)\n",
    "    contact_vector = []\n",
    "    for channel_idx, channel in enumerate(channel_ids):\n",
    "        x_coord, y_coord = (int(channel.split('-')[0]) - 1) * dist_multiplier, (int(channel.split('-')[1]) - 1) * dist_multiplier\n",
    "        positions[channel_idx, 1], positions[channel_idx, 0] = x_coord, y_coord\n",
    "        \n",
    "        contact_vector.append((0, x_coord,   y_coord, 'circle', circle_radius, '', '', channel_idx, 'um', 1., 0., 0., 1.))\n",
    "\n",
    "    # later if we are using peak detection, we may need it\n",
    "    recording.set_channel_locations(locations=positions)\n",
    "\n",
    "    probe = Probe(ndim=2, si_units='um')\n",
    "    probe.set_contacts(positions=positions, shapes='circle', shape_params={'radius': circle_radius})\n",
    "    probe.device_channel_indices = np.arange(len(channel_ids))\n",
    "    probe.create_auto_shape('rect')\n",
    "\n",
    "    recording.set_probe(probe)\n",
    "\n",
    "\n",
    "    # Create contact_vector\n",
    "    dtypes=[('probe_index', '<i8'), ('x', '<f8'), ('y', '<f8'), ('contact_shapes', '<U64'), \n",
    "            ('radius', '<f8'), ('shank_ids', '<U64'), ('contact_ids', '<U64'), ('device_channel_indices', '<i8'), \n",
    "            ('si_units', '<U64'), ('plane_axis_x_0', '<f8'), ('plane_axis_x_1', '<f8'), ('plane_axis_y_0', '<f8'), \n",
    "            ('plane_axis_y_1', '<f8')]\n",
    "\n",
    "    recording.set_property('contact_vector', np.asarray(contact_vector, dtype=dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_peaks(root, sample_base, well):\n",
    "    session_token = dt.datetime.now().strftime(\"%y-%m-%d\") + '_' + \\\n",
    "                ''.join(random.choice(string.ascii_letters) for i in range(8)) + str(well[0]) + '-' + str(well[1])\n",
    "    \n",
    "    recording = load_recording_from_raw(root=root, sample_base=sample_base, well=well, time_samplings_to_mask=[])\n",
    "    load_probe_recording(recording=recording, type_MEAS=16)\n",
    "    \n",
    "    recording_bin = recording.save(n_jobs=16, chunk_duration=\"1s\", folder=f'tmp/bin_{session_token}')\n",
    "\n",
    "    recording_f = spre.bandpass_filter(recording_bin, freq_min=300, freq_max=5000)\n",
    "\n",
    "    recording_cmr = spre.common_reference(recording_f, reference='global', operator='median')\n",
    "\n",
    "    noise_levels = si.get_noise_levels(recording_cmr, return_scaled=False)\n",
    "\n",
    "    peaks = detect_peaks(recording_cmr,\n",
    "                        method='locally_exclusive',\n",
    "                        local_radius_um=450, \n",
    "                        detect_threshold=5,\n",
    "                        noise_levels=noise_levels,\n",
    "                        )\n",
    "    \n",
    "    list_peaks = []\n",
    "    list_electrodes = []\n",
    "\n",
    "    for i in range(16):\n",
    "        list_peaks_i = [peak[0] / recording.sampling_frequency for peak in peaks if peak[1] == i]\n",
    "        list_peaks += list_peaks_i\n",
    "\n",
    "        el_x, el_y = i // 4, i % 4\n",
    "        list_electrodes += [f'{el_x + 1}{el_y + 1}'] * len(list_peaks_i)\n",
    "\n",
    "    return list_peaks, list_electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = '2024_05_07'\n",
    "MV = 500\n",
    "\n",
    "folder_base = f'/data/Proyectos/Nanoneuro_exps_ane/raw_files/{DATE}/{MV}/'\n",
    "folder_df_save = f'/data/Proyectos/Nanoneuro_exps_ane/results/{DATE}/{MV}/'\n",
    "\n",
    "os.makedirs(folder_df_save, exist_ok=True)\n",
    "\n",
    "list_conditions = [#('Condition', 'Treatment', 'Wells', 'Well_num', 'Folder') \n",
    "                    ('CTRL', 'PRE',   ['A1', 'A2', 'A3'], ['11', '12', '13'], 'D24_POSTsiembra_P2_(000)'), \n",
    "                    ('CTRL', 'POST',  ['A1', 'A2', 'A3'], ['11', '12', '13'], 'D24_POSTsiembra_P2_POSTexperimento(000)'),\n",
    "                    ('BP', 'PRE',     ['A4', 'A5', 'A6'], ['14', '15', '16'], 'D24_POSTsiembra_P2_(000)'), \n",
    "                    ('BP', 'POST',    ['A4', 'A5', 'A6'], ['14', '15', '16'], 'D24_POSTsiembra_P2_POSTexperimento(000)'), \n",
    "                    ('LINK1', 'PRE',  ['B1', 'B2', 'B3'], ['21', '22', '23'], 'D24_POSTsiembra_P2_(000)'), \n",
    "                    ('LINK1', 'POST', ['B1', 'B2', 'B3'], ['21', '22', '23'], 'D24_POSTsiembra_P2_POSTexperimento(000)'),\n",
    "                    ('LINK2', 'PRE',  ['C1', 'C2', 'C3'], ['31', '32', '33'], 'D24_POSTsiembra_P2_(000)'), \n",
    "                    ('LINK2', 'POST', ['C1', 'C2', 'C3'], ['31', '32', '33'], 'D24_POSTsiembra_P2_POSTexperimento(000)'),\n",
    "                    ('LINK3', 'PRE',  ['D1', 'D2', 'D3'], ['41', '42', '43'], 'D24_POSTsiembra_P2_(000)'), \n",
    "                    ('LINK3', 'POST', ['D1', 'D2', 'D3'], ['41', '42', '43'], 'D24_POSTsiembra_P2_POSTexperimento(000)'),\n",
    "                    ('BP+LINK1', 'PRE',  ['B4', 'B5', 'B6'], ['24', '25', '26'], 'D25_POSTsiembra_P2(000)'), \n",
    "                    ('BP+LINK1', 'POST', ['B4', 'B5', 'B6'], ['24', '25', '26'], 'D25_POSTsiembra_P2_POSTexperiment(001)'),\n",
    "                    ('BP+LINK2', 'PRE',  ['C4', 'C5', 'C6'], ['34', '35', '36'], 'D25_POSTsiembra_P2(000)'), \n",
    "                    ('BP+LINK2', 'POST', ['C4', 'C5', 'C6'], ['34', '35', '36'], 'D25_POSTsiembra_P2_POSTexperiment(001)'),\n",
    "                    ('BP+LINK3', 'PRE',  ['D4', 'D5', 'D6'], ['44', '45', '46'], 'D25_POSTsiembra_P2(000)'), \n",
    "                    ('BP+LINK3', 'POST', ['D4', 'D5', 'D6'], ['44', '45', '46'], 'D25_POSTsiembra_P2_POSTexperiment(001)'),\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks = pd.DataFrame(columns=['condition', 'treatment', 'well', 'well_num', 'electrode', 'time'])\n",
    "\n",
    "for condition, treatment, list_wells, list_wells_num, sample_base in list_conditions:\n",
    "    for well, well_num in zip(list_wells, list_wells_num):\n",
    "        print(condition, treatment, well, well_num, sample_base)\n",
    "        list_peak_times, list_electrodes = retrieve_peaks(root=folder_base, sample_base=sample_base, well=(int(well_num[0]), int(well_num[1])))\n",
    "        \n",
    "        df_peaks_i = pd.DataFrame({'condition': [condition] * len(list_peak_times), \n",
    "                                    'treatment': [treatment] * len(list_peak_times), \n",
    "                                    'well': [well] * len(list_peak_times), \n",
    "                                    'well_num': [well_num] * len(list_peak_times), \n",
    "                                    'electrode': list_electrodes, \n",
    "                                    'time': list_peak_times\n",
    "                                    })\n",
    "        \n",
    "        df_peaks = pd.concat([df_peaks, df_peaks_i]).reset_index(drop=True)\n",
    "        print(len(df_peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks.to_csv(f'{folder_df_save}/df_peaks_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load df peaks and remove non-compliant electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks = pd.read_csv(f'{folder_df_save}/df_peaks_full.csv')\n",
    "df_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each well\n",
    "df_peaks_sub = df_peaks[(df_peaks['condition'] == 'CTRL') & \n",
    "                        (df_peaks['treatment'] == 'PRE') & \n",
    "                        (df_peaks['well'] == 'A1')]\n",
    "\n",
    "df_peaks_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 6))\n",
    "\n",
    "y = [(int(i[0]) - 1) * 4 + (int(i[1]) - 1) for i in df_peaks_sub['electrode'].astype(str).values]\n",
    "x =  df_peaks_sub['time'].values \n",
    "\n",
    "plt.yticks(np.arange(16), [f'{i//4 + 1}{i%4 + 1}' for i in np.arange(16)])\n",
    "\n",
    "plt.scatter(x, y, marker='|', alpha=0.15)\n",
    "\n",
    "# plt.xlim([10, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE A LIST OF ELECTRODES TO REFUSE\n",
    "# Since each condition has a different set of wells, we only need to encode the well info\n",
    "\n",
    "dict_electrode_refuse = {'A1': ['42', '32'],\n",
    "                         'A2': [],\n",
    "                         'A3': [],\n",
    "                         'A4': [],\n",
    "                         'A5': [],\n",
    "                         'A6': [],\n",
    "                         'B1': [],\n",
    "                         'B2': [],\n",
    "                         'B3': [],\n",
    "                         'B4': [],\n",
    "                         'B5': [],\n",
    "                         'B6': [],\n",
    "                         'C1': [],\n",
    "                         'C2': [],\n",
    "                         'C3': [],\n",
    "                         'C4': [],\n",
    "                         'C5': [],\n",
    "                         'C6': [],\n",
    "                         'D1': [],\n",
    "                         'D2': [],\n",
    "                         'D3': [],\n",
    "                         'D4': [],\n",
    "                         'D5': [],\n",
    "                         'D6': [],}\n",
    "\n",
    "list_remove_idx = []\n",
    "\n",
    "for well, list_electrodes in dict_electrode_refuse.items():\n",
    "    for electrode in list_electrodes:\n",
    "        df_sub = df_peaks[(df_peaks['well'] == well) & (df_peaks['electrode'] == int(electrode))]\n",
    "        list_remove_idx += df_sub.index.tolist()\n",
    "\n",
    "list_remove_idx_bool = np.ones(len(df_peaks)).astype(bool)\n",
    "list_remove_idx_bool[list_remove_idx] = False\n",
    "\n",
    "df_peaks_sub_filter = df_peaks.loc[list_remove_idx_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks_sub_filter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoneuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
