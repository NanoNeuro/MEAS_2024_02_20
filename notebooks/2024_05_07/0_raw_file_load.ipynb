{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import scipy.stats as sts\n",
    "\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si  # import core only\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.curation as scur\n",
    "import spikeinterface.widgets as sw\n",
    "from spikeinterface.sortingcomponents.peak_detection import detect_peaks\n",
    "from spikeinterface.sortingcomponents.peak_localization import localize_peaks\n",
    "\n",
    "from typing import Tuple, List\n",
    "from probeinterface import Probe\n",
    "\n",
    "def load_recording_from_raw(root: str, sample_base: str, well: Tuple[int, int], time_samplings_to_mask: List[Tuple[float, float]]):\n",
    "\n",
    "    traces_list = []\n",
    "    channel_ids = []\n",
    "\n",
    "    df = pd.read_csv(f'{root}/{sample_base}/{sample_base}.info', index_col=0, names=['index', 'value'], sep='\\t')\n",
    "    sampling_frequency = df.loc['SamplingFrequency', 'value']\n",
    "    voltage_scale = np.abs(df.loc['VoltageScale', 'value'])\n",
    "\n",
    "    # We choose 10 here because in 64-electrode MEAs the range would be up to 9. \n",
    "    # Since the time required for the non-existing electrodes is small, we don't mine using a larger number.\n",
    "    for Erow in range(1,10):  \n",
    "        for Ecol in range(1,10):\n",
    "            filename = f'{root}/{sample_base}/{well[0]}-{well[1]}-{Erow}-{Ecol}_voltageRaw'\n",
    "            is_txt, is_gzip = os.path.exists(f'{filename}.txt'), os.path.exists(f'{filename}.txt.gz') \n",
    "\n",
    "            if is_txt or is_gzip:\n",
    "                channel_ids.append(f'{Erow}-{Ecol}')\n",
    "                \n",
    "                if is_txt:\n",
    "                    list_voltages = np.loadtxt(f'{filename}.txt')\n",
    "                elif is_gzip:\n",
    "                    list_voltages = np.loadtxt(f'{filename}.txt.gz')\n",
    "\n",
    "                traces_list.append(list_voltages)\n",
    "            \n",
    "\n",
    "    trace_array = np.asarray(traces_list).transpose() / voltage_scale\n",
    "\n",
    "    for time_sampling in time_samplings_to_mask:\n",
    "        t0 = int(time_sampling[0] * sampling_frequency)\n",
    "        tf = int(time_sampling[1] * sampling_frequency)\n",
    "        trace_array[t0:tf, :] = 0\n",
    "\n",
    "    sample_recording = si.NumpyRecording(\n",
    "        traces_list=[trace_array],\n",
    "        sampling_frequency=sampling_frequency,\n",
    "        channel_ids=np.asarray(channel_ids)\n",
    "    )\n",
    "\n",
    "    sample_recording.set_property('group', [0] * len(channel_ids))\n",
    "    sample_recording.is_dumpable = True  # This is necessary for some options later, like spike sorting\n",
    "\n",
    "    return sample_recording\n",
    "\n",
    "\n",
    "def load_probe_recording(recording: si.NumpyRecording, type_MEAS: int, ):\n",
    "    dist_multiplier = 350 if type_MEAS == 16 else 300\n",
    "    circle_radius = 50\n",
    "\n",
    "    channel_ids = recording.get_channel_ids()\n",
    "\n",
    "    positions = np.zeros((len(channel_ids), 2), dtype=float)\n",
    "    contact_vector = []\n",
    "    for channel_idx, channel in enumerate(channel_ids):\n",
    "        x_coord, y_coord = (int(channel.split('-')[0]) - 1) * dist_multiplier, (int(channel.split('-')[1]) - 1) * dist_multiplier\n",
    "        positions[channel_idx, 1], positions[channel_idx, 0] = x_coord, y_coord\n",
    "        \n",
    "        contact_vector.append((0, x_coord,   y_coord, 'circle', circle_radius, '', '', channel_idx, 'um', 1., 0., 0., 1.))\n",
    "\n",
    "    # later if we are using peak detection, we may need it\n",
    "    recording.set_channel_locations(locations=positions)\n",
    "\n",
    "    probe = Probe(ndim=2, si_units='um')\n",
    "    probe.set_contacts(positions=positions, shapes='circle', shape_params={'radius': circle_radius})\n",
    "    probe.device_channel_indices = np.arange(len(channel_ids))\n",
    "    probe.create_auto_shape('rect')\n",
    "\n",
    "    recording.set_probe(probe)\n",
    "\n",
    "\n",
    "    # Create contact_vector\n",
    "    dtypes=[('probe_index', '<i8'), ('x', '<f8'), ('y', '<f8'), ('contact_shapes', '<U64'), \n",
    "            ('radius', '<f8'), ('shank_ids', '<U64'), ('contact_ids', '<U64'), ('device_channel_indices', '<i8'), \n",
    "            ('si_units', '<U64'), ('plane_axis_x_0', '<f8'), ('plane_axis_x_1', '<f8'), ('plane_axis_y_0', '<f8'), \n",
    "            ('plane_axis_y_1', '<f8')]\n",
    "\n",
    "    recording.set_property('contact_vector', np.asarray(contact_vector, dtype=dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_peaks(root, sample_base, well):\n",
    "    session_token = dt.datetime.now().strftime(\"%y-%m-%d\") + '_' + \\\n",
    "                ''.join(random.choice(string.ascii_letters) for i in range(8)) + str(well[0]) + '-' + str(well[1])\n",
    "    \n",
    "    recording = load_recording_from_raw(root=root, sample_base=sample_base, well=well, time_samplings_to_mask=[])\n",
    "    load_probe_recording(recording=recording, type_MEAS=16)\n",
    "    \n",
    "    recording_bin = recording.save(n_jobs=16, chunk_duration=\"1s\", folder=f'tmp/bin_{session_token}')\n",
    "\n",
    "    recording_f = spre.bandpass_filter(recording_bin, freq_min=300, freq_max=5000)\n",
    "\n",
    "    recording_cmr = spre.common_reference(recording_f, reference='global', operator='median')\n",
    "\n",
    "    noise_levels = si.get_noise_levels(recording_cmr, return_scaled=False)\n",
    "\n",
    "    peaks = detect_peaks(recording_cmr,\n",
    "                        method='locally_exclusive',\n",
    "                        local_radius_um=450, \n",
    "                        detect_threshold=5,\n",
    "                        noise_levels=noise_levels,\n",
    "                        )\n",
    "    \n",
    "    list_peaks = []\n",
    "    list_electrodes = []\n",
    "\n",
    "    for i in range(16):\n",
    "        list_peaks_i = [peak[0] / recording.sampling_frequency for peak in peaks if peak[1] == i]\n",
    "        list_peaks += list_peaks_i\n",
    "\n",
    "        el_x, el_y = i // 4, i % 4\n",
    "        list_electrodes += [f'{el_x + 1}{el_y + 1}'] * len(list_peaks_i)\n",
    "\n",
    "    return list_peaks, list_electrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN ONLY ONE CELL (100, 200 or 500)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = '2024_05_07'\n",
    "MV = 100\n",
    "\n",
    "folder_base = f'/data/Proyectos/Nanoneuro_exps_ane/raw_files/{DATE}/{MV}/'\n",
    "folder_df_save = f'/data/Proyectos/Nanoneuro_exps_ane/results/{DATE}/{MV}/'\n",
    "\n",
    "os.makedirs(folder_df_save, exist_ok=True)\n",
    "\n",
    "list_conditions = [#('Condition', 'Treatment', 'Wells', 'Well_num', 'Replicate', 'Folder') \n",
    "                    ('BP',          'PRE',     ['C5', 'C6'],               [35, 36],           [1, 2],         ''), \n",
    "                    ('BP',          'POST',    ['C5', 'C6'],               [35, 36],           [1, 2],         ''), \n",
    "                    ('LINK1',       'PRE',     ['D2'],                     [42],               [1],            ''), \n",
    "                    ('LINK1',       'POST',    ['D2'],                     [42],               [1],            ''), \n",
    "                    ('LINK2',       'PRE',     ['D3', 'D4'],               [43, 44],           [1, 2],         ''), \n",
    "                    ('LINK2',       'POST',    ['D3', 'D4'],               [43, 44],           [1, 2],         ''),\n",
    "                    ('LINK3',       'PRE',     ['D5', 'D6'],               [45, 46],           [1, 2],         ''),\n",
    "                    ('LINK3',       'POST',    ['D5', 'D6'],               [45, 46],           [1, 2],         ''),\n",
    "                    ('BP+LINK1',    'PRE',     ['A1', 'A2', 'A3', 'A4'],   [11, 12, 13, 14],   [1, 2, 3, 4],   ''), \n",
    "                    ('BP+LINK1',    'POST',    ['A1', 'A2', 'A3', 'A4'],   [11, 12, 13, 14],   [1, 2, 3, 4],   ''), \n",
    "                    ('BP+LINK2',    'PRE',     ['B2', 'B3', 'B4'],         [22, 23, 24],       [1, 2, 3],      ''), \n",
    "                    ('BP+LINK2',    'POST',    ['B2', 'B3', 'B4'],         [22, 23, 24],       [1, 2, 3],      ''), \n",
    "                    ('BP+LINK3',    'PRE',     ['C2', 'C3', 'C4'],         [32, 33, 34],       [1, 2, 3],      ''), \n",
    "                    ('BP+LINK3',    'POST',    ['C2', 'C3', 'C4'],         [32, 33, 34],       [1, 2, 3],      ''), \n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = '2024_05_07'\n",
    "MV = 200\n",
    "\n",
    "folder_base = f'/data/Proyectos/Nanoneuro_exps_ane/raw_files/{DATE}/{MV}/'\n",
    "folder_df_save = f'/data/Proyectos/Nanoneuro_exps_ane/results/{DATE}/{MV}/'\n",
    "\n",
    "os.makedirs(folder_df_save, exist_ok=True)\n",
    "\n",
    "list_conditions = [#('Condition', 'Treatment', 'Wells', 'Well_num', 'Replicate', 'Folder') \n",
    "                    ('CTRL',        'PRE',     ['A1', 'A2', 'A3'],     [11, 12, 13], [1, 2, 3], ''), \n",
    "                    ('CTRL',        'POST',    ['A1', 'A2', 'A3'],     [11, 12, 13], [1, 2, 3], ''), \n",
    "                    ('BP',          'PRE',     ['A4', 'A5', 'A6'],     [14, 15, 16], [1, 2, 3], ''), \n",
    "                    ('BP',          'POST',    ['A4', 'A5', 'A6'],     [14, 15, 16], [1, 2, 3], ''),\n",
    "                    ('LINK1',       'PRE',     ['B4', 'B5', 'B6'],     [25, 25, 26], [1, 2, 3], ''), \n",
    "                    ('LINK1',       'POST',    ['B4', 'B5', 'B6'],     [25, 25, 26], [1, 2, 3], ''), \n",
    "                    ('LINK2',       'PRE',     ['C3',' C4', 'C6'],     [33, 34, 36], [1, 2, 3], ''), \n",
    "                    ('LINK2',       'POST',    ['C3',' C4', 'C6'],     [33, 34, 36], [1, 2, 3], ''), \n",
    "                    ('LINK3',       'PRE',     ['D4', 'D5', 'D6'],     [44, 45, 46], [1, 2, 3], ''), \n",
    "                    ('LINK3',       'POST',    ['D4', 'D5', 'D6'],     [44, 45, 46], [1, 2, 3], ''), \n",
    "                    ('BP+LINK1',    'PRE',     ['B1', 'B2', 'B3'],     [21, 22, 23], [1, 2, 3], ''), \n",
    "                    ('BP+LINK1',    'POST',    ['B1', 'B2', 'B3'],     [21, 22, 23], [1, 2, 3], ''), \n",
    "                    ('BP+LINK2',    'PRE',     ['C1', 'C2', 'C5'],     [21, 32, 35], [1, 2, 3], ''), \n",
    "                    ('BP+LINK2',    'POST',    ['C1', 'C2', 'C5'],     [21, 32, 35], [1, 2, 3], ''), \n",
    "                    ('BP+LINK3',    'PRE',     ['D1', 'D2', 'D3'],     [41, 42, 43], [1, 2, 3], ''), \n",
    "                    ('BP+LINK3',    'POST',    ['D1', 'D2', 'D3'],     [41, 42, 43], [1, 2, 3], ''), \n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = '2024_05_07'\n",
    "MV = 500\n",
    "\n",
    "folder_base = f'/data/Proyectos/Nanoneuro_exps_ane/raw_files/{DATE}/{MV}/'\n",
    "folder_df_save = f'/data/Proyectos/Nanoneuro_exps_ane/results/{DATE}/{MV}/'\n",
    "\n",
    "os.makedirs(folder_df_save, exist_ok=True)\n",
    "\n",
    "list_conditions = [#('Condition', 'Treatment', 'Wells', 'Well_num', 'Replicate', 'Folder') \n",
    "                    ('CTRL',        'PRE',      ['A1', 'A2', 'A3'], ['11', '12', '13'], [1, 2, 3], 'PRE'), \n",
    "                    ('CTRL',        'POST',     ['A1', 'A2', 'A3'], ['11', '12', '13'], [1, 2, 3], 'POST'),\n",
    "                    ('BP',          'PRE',      ['A4', 'A5', 'A6'], ['14', '15', '16'], [1, 2, 3], 'PRE'), \n",
    "                    ('BP',          'POST',     ['A4', 'A5', 'A6'], ['14', '15', '16'], [1, 2, 3], 'POST'), \n",
    "                    ('LINK1',       'PRE',      ['B1', 'B2', 'B3'], ['21', '22', '23'], [1, 2, 3], 'PRE'), \n",
    "                    ('LINK1',       'POST',     ['B1', 'B2', 'B3'], ['21', '22', '23'], [1, 2, 3], 'POST'),\n",
    "                    ('LINK2',       'PRE',      ['C1', 'C2', 'C3'], ['31', '32', '33'], [1, 2, 3], 'PRE'), \n",
    "                    ('LINK2',       'POST',     ['C1', 'C2', 'C3'], ['31', '32', '33'], [1, 2, 3], 'POST'),\n",
    "                    ('LINK3',       'PRE',      ['D1', 'D2', 'D3'], ['41', '42', '43'], [1, 2, 3], 'PRE'), \n",
    "                    ('LINK3',       'POST',     ['D1', 'D2', 'D3'], ['41', '42', '43'], [1, 2, 3], 'POST'),\n",
    "                    ('BP+LINK1',    'PRE',      ['B4', 'B5', 'B6'], ['24', '25', '26'], [1, 2, 3], 'PRE'), \n",
    "                    ('BP+LINK1',    'POST',     ['B4', 'B5', 'B6'], ['24', '25', '26'], [1, 2, 3], 'POST'),\n",
    "                    ('BP+LINK2',    'PRE',      ['C4', 'C5', 'C6'], ['34', '35', '36'], [1, 2, 3], 'PRE'), \n",
    "                    ('BP+LINK2',    'POST',     ['C4', 'C5', 'C6'], ['34', '35', '36'], [1, 2, 3], 'POST'),\n",
    "                    ('BP+LINK3',    'PRE',      ['D4', 'D5', 'D6'], ['44', '45', '46'], [1, 2, 3], 'PRE'), \n",
    "                    ('BP+LINK3',    'POST',     ['D4', 'D5', 'D6'], ['44', '45', '46'], [1, 2, 3], 'POST'),\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks = pd.DataFrame(columns=['condition', 'treatment', 'well', 'well_num', 'replicate', 'electrode', 'time'])\n",
    "\n",
    "for condition, treatment, list_wells, list_wells_num, replicates, sample_base in list_conditions:\n",
    "    for well, well_num, replicate in zip(list_wells, list_wells_num, replicates):\n",
    "        print(condition, treatment, well, well_num, replicate, sample_base)\n",
    "        list_peak_times, list_electrodes = retrieve_peaks(root=folder_base, sample_base=sample_base, well=(int(well_num[0]), int(well_num[1])))\n",
    "        \n",
    "        df_peaks_i = pd.DataFrame({'condition': [condition] * len(list_peak_times), \n",
    "                                    'treatment': [treatment] * len(list_peak_times), \n",
    "                                    'well': [well] * len(list_peak_times), \n",
    "                                    'well_num': [well_num] * len(list_peak_times), \n",
    "                                    'replicate': [replicate] * len(list_peak_times), \n",
    "                                    'electrode': list_electrodes, \n",
    "                                    'time': list_peak_times\n",
    "                                    })\n",
    "        \n",
    "        df_peaks = pd.concat([df_peaks, df_peaks_i]).reset_index(drop=True)\n",
    "        print(len(df_peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks.to_csv(f'{folder_df_save}/df_peaks_full_{MV}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load df peaks and remove non-compliant electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks = pd.read_csv(f'{folder_df_save}/df_peaks_full_{MV}.csv')\n",
    "df_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks['replicate'] = [(int(i[1]) - 1) % 3 for i in df_peaks['well'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each well\n",
    "df_peaks_sub = df_peaks[(df_peaks['treatment'] == 'POST') & \n",
    "                        (df_peaks['well'] == 'B5')]\n",
    "\n",
    "fig = plt.figure(figsize=(30, 6))\n",
    "\n",
    "y = [(int(i[0]) - 1) * 4 + (int(i[1]) - 1) for i in df_peaks_sub['electrode'].astype(str).values]\n",
    "x =  df_peaks_sub['time'].values \n",
    "\n",
    "plt.yticks(np.arange(16), [f'{i//4 + 1}{i%4 + 1}' for i in np.arange(16)])\n",
    "\n",
    "plt.scatter(x, y, marker='|', alpha=0.15)\n",
    "\n",
    "# plt.xlim([10, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE A LIST OF ELECTRODES TO REFUSE\n",
    "# Since each condition has a different set of wells, we only need to encode the well info\n",
    "\n",
    "# We are going to refuse electrodes with less than 60 spikes per minute.\n",
    "\n",
    "min_spikes = 60\n",
    "\n",
    "dict_electrode_refuse = {}\n",
    "\n",
    "\n",
    "for well in sorted(set(df_peaks['well'].values)):\n",
    "    list_electrodes_refuse = []\n",
    "\n",
    "    df_well = df_peaks[df_peaks['well'] == well]\n",
    "\n",
    "    for treatment in sorted(set(df_well['treatment'].values)):\n",
    "        df_well_treatment = df_well[df_well['treatment'] == treatment]\n",
    "\n",
    "        list_counts = df_well_treatment.groupby('electrode').count()['time'].sort_values() * 60 / (df_peaks_sub['time'].max() - df_peaks_sub['time'].min())\n",
    "        list_electrodes = list_counts[list_counts < 60].index.tolist()\n",
    "\n",
    "        list_electrodes_refuse += list_electrodes\n",
    "\n",
    "    set_electrodes_refuse = sorted(list(set(list_electrodes_refuse)))\n",
    "    dict_electrode_refuse[well] = set_electrodes_refuse\n",
    "        \n",
    "\n",
    "print(dict_electrode_refuse)\n",
    "\n",
    "\n",
    "list_remove_idx = []\n",
    "\n",
    "for well, list_electrodes in dict_electrode_refuse.items():\n",
    "    for electrode in list_electrodes:\n",
    "        df_sub = df_peaks[(df_peaks['well'] == well) & (df_peaks['electrode'] == int(electrode))]\n",
    "        list_remove_idx += df_sub.index.tolist()\n",
    "\n",
    "list_remove_idx_bool = np.ones(len(df_peaks)).astype(bool)\n",
    "list_remove_idx_bool[list_remove_idx] = False\n",
    "\n",
    "df_peaks_sub_filter = df_peaks.loc[list_remove_idx_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks_sub_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative change in MFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MFR = df_peaks_sub_filter.groupby(['condition', 'treatment', 'well', 'replicate', 'electrode']).count()['time'] / (df_peaks_sub_filter['time'].max() - df_peaks_sub_filter['time'].min())\n",
    "df_MFR = df_MFR.reset_index().sort_values(by=['well', 'electrode'])\n",
    "df_MFR = df_MFR.rename(columns={'time': 'MFR'})\n",
    "df_MFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MFR[df_MFR['treatment'] == 'POST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MFR_ratio = df_MFR[df_MFR['treatment'] == 'POST']\n",
    "\n",
    "ratios = df_MFR[df_MFR['treatment'] == 'POST']['MFR'].values /  df_MFR[df_MFR['treatment'] == 'PRE']['MFR'].values\n",
    "\n",
    "df_MFR_ratio.loc[:, 'PRE'] = df_MFR[df_MFR['treatment'] == 'PRE'].loc[:, 'MFR'].values\n",
    "df_MFR_ratio.loc[:, 'POST'] = df_MFR[df_MFR['treatment'] == 'POST'].loc[:, 'MFR'].values\n",
    "df_MFR_ratio['mean_PRE_POST'] = (df_MFR_ratio['PRE'] + df_MFR_ratio['POST']) / 2\n",
    "\n",
    "df_MFR_ratio = df_MFR_ratio.rename(columns={'MFR': 'MFR_ratio'})[['condition', 'well', 'replicate', 'electrode', 'PRE', 'POST', 'mean_PRE_POST', 'MFR_ratio']]\n",
    "df_MFR_ratio['MFR_ratio'] = ratios * 100\n",
    "\n",
    "df_MFR_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(19,6))\n",
    "sns.swarmplot(data = df_MFR_ratio, x='condition', y='MFR_ratio', hue='replicate')\n",
    "plt.plot([-0.5, 7.5], [100, 100], c='#bc0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(19,6))\n",
    "sns.boxplot(data = df_MFR_ratio, x='condition', y='MFR_ratio')\n",
    "plt.plot([-0.5, 7.5], [100, 100], c='#bc0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = df_MFR_ratio, x='PRE', y='MFR_ratio', label='PRE')\n",
    "sns.scatterplot(data = df_MFR_ratio, x='POST', y='MFR_ratio', label='POST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create regplot\n",
    "p = sns.regplot(data = df_MFR_ratio, x='mean_PRE_POST', y='MFR_ratio')\n",
    "\n",
    "#calculate slope and intercept of regression equation\n",
    "slope, intercept, r, p, sterr = sts.linregress(x=p.get_lines()[0].get_xdata(),\n",
    "                                                       y=p.get_lines()[0].get_ydata())\n",
    "\n",
    "#display slope and intercept of regression equation\n",
    "print(intercept, slope, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of ISIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ISIs = pd.DataFrame(columns=df_peaks_sub_filter.columns)\n",
    "list_wells = df_peaks_sub_filter['well'].drop_duplicates().values \n",
    "\n",
    "for well in list_wells:\n",
    "    df_well = df_peaks_sub_filter[df_peaks_sub_filter['well'] == well]\n",
    "    list_electrodes = df_well['electrode'].drop_duplicates().values \n",
    "\n",
    "    for electrode in list_electrodes:\n",
    "        df_well_electrode = df_well[df_well['electrode'] == electrode].copy()\n",
    "        diff_times = df_well_electrode['time'].iloc[1:].values - df_well_electrode['time'].iloc[:-1].values\n",
    "\n",
    "        df_well_electrode.loc[df_well_electrode.index[:-1], 'time'] = diff_times\n",
    "\n",
    "        df_ISIs = pd.concat([df_ISIs, df_well_electrode.iloc[:-1]])\n",
    "\n",
    "df_ISIs['cond-treat'] = df_ISIs['condition'] + '-' + df_ISIs['treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_plot(df_ISIs, x_col, g_col, log=True):\n",
    "    sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "    # Create the data\n",
    "    df = pd.DataFrame(dict(x=df_ISIs[x_col].values, g=df_ISIs[g_col].values))\n",
    "    df = df[df['x'] > 0]\n",
    "\n",
    "    # Initialize the FacetGrid object\n",
    "    pal = sns.cubehelix_palette(len(df_ISIs[g_col].drop_duplicates().values), rot=-.25, light=.7)\n",
    "    g = sns.FacetGrid(df, row=\"g\", hue=\"g\", aspect=15, height=.5, palette=pal)\n",
    "\n",
    "    # Draw the densities in a few steps\n",
    "    g.map(sns.kdeplot, \"x\", log_scale=log, \n",
    "        bw_adjust=.5, clip_on=False,\n",
    "        fill=True, alpha=1, linewidth=1.5)\n",
    "    g.map(sns.kdeplot, \"x\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5, log_scale=log,)\n",
    "\n",
    "    # passing color=None to refline() uses the hue mapping\n",
    "    g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "\n",
    "    # Define and use a simple function to label the plot in axes coordinates\n",
    "    def label(x, color, label):\n",
    "        ax = plt.gca()\n",
    "        ax.text(0, .2, label, fontweight=\"bold\", color=color,\n",
    "                ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "\n",
    "    g.map(label, \"x\")\n",
    "\n",
    "    # Set the subplots to overlap\n",
    "    g.figure.subplots_adjust(hspace=-.25)\n",
    "\n",
    "    # Remove axes details that don't play well with overlap\n",
    "    g.set_titles(\"\")\n",
    "    g.set(yticks=[], ylabel=\"\")\n",
    "    g.despine(bottom=True, left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plot(df_ISIs, x_col='time', g_col='well', log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plot(df_ISIs, x_col='time', g_col='cond-treat', log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plot(df_ISIs[(df_ISIs['time'] > 0.3) & (df_ISIs['time'] < 5)], x_col='time', g_col='well', log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plot(df_ISIs[(df_ISIs['time'] > 0.5) & (df_ISIs['time'] < 5)], \n",
    "         x_col='time', g_col='cond-treat', log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Burst frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = 0.1\n",
    "cutoff_counts = 60\n",
    "\n",
    "time_ranges = np.arange(np.min(df_laser['start_times']) , np.max(df_laser['end_times']) , tw)\n",
    "time_ranges_mean = (time_ranges[1:] + time_ranges[:-1]) * 0.5 \n",
    "\n",
    "counts = np.array([len(df_spikes[(df_spikes['Time (s)'] >= start) & (df_spikes['Time (s)'] < end)]) for start, end in zip(time_ranges[:-1], time_ranges[1: ])])\n",
    "len(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoneuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
