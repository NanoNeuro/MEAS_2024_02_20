{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es plotear y analizar tiempos / spikes de experimentos. Por un lado cargamos un archivo donde se indica el tiempo de activación del láser, y por otro tenemos los spikes. Tenemos que plotear primero, de manera coordinada, la información de ambos archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoy = dt.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = '../../../results'\n",
    "TIEMPOS_ESTRUCTURA_FOLDER = '../../../tiempos_structura'\n",
    "SPIKE_LIST_DIR = '../../../spike_lists'\n",
    "\n",
    "CUTOFF_SPIKES_HZ = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times = pd.read_csv('2024_06_07_P2', sep=', ', index_col='FileName')\n",
    "df_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_date = '2024_06_07_P2'\n",
    "\n",
    "name_sample = 'D52_POSTsiembra_P2_A2_100(000)'\n",
    "name_file_spikes = f'{name_sample}_spike_list.csv'\n",
    "name_file_laser = '2024067_MEAs_A2_100msec.csv'\n",
    "\n",
    "column_time = 'AddedDate'\n",
    "\n",
    "timestamp = [int(i) for i in df_times[column_time].loc[name_sample].split(':')]\n",
    "\n",
    "time_absolute_start = dt.datetime.combine(hoy, dt.time(timestamp[0], timestamp[1], timestamp[2], timestamp[3] * 1000))  # A1_(IV)_(000)\n",
    "\n",
    "time_window_seconds = 0.28         # We add a custom window to displace the times of the lasers, because we see that in some cases the laser start time is not correct\n",
    "\n",
    "os.makedirs(f'{RESULTS_FOLDER}/{exp_date}/{column_time}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spikes = pd.read_csv(f\"{SPIKE_LIST_DIR}/{exp_date}/{name_file_spikes}\", sep=None, #Use sep=None to recognize the separator automatically, because in some files it is ; and in other it is \\t\n",
    "                        encoding='unicode_escape', \n",
    "                        skipfooter=9) # we use ski_footer because there are 9 lines in the end of the file that are outputed automatically by the MEAs and which yield an error when loaded\n",
    "\n",
    "df_spikes['electrode_str'] = [i.split('_')[1] for i in df_spikes['Electrode']]\n",
    "df_spikes['electrode_coord'] = [(int(electrode[0]) - 1, 3 - (int(electrode[1]) - 1)) for electrode in df_spikes['electrode_str']]\n",
    "df_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter electrodes with low activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE A LIST OF ELECTRODES TO REFUSE\n",
    "# Since each condition has a different set of wells, we only need to encode the well info\n",
    "\n",
    "# We are going to refuse electrodes with less than XX spikes PER MINUTE.\n",
    "\n",
    "list_counts = df_spikes.groupby('Electrode').count()['Time (s)'].sort_values() / \\\n",
    "    (df_spikes['Time (s)'].max() - df_spikes['Time (s)'].min()) \n",
    "list_electrodes_remain = list_counts[list_counts > CUTOFF_SPIKES_HZ].index.tolist()\n",
    "\n",
    "df_spikes_filter = df_spikes[df_spikes['Electrode'].isin(list_electrodes_remain)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laser = pd.read_csv(f\"{TIEMPOS_ESTRUCTURA_FOLDER}/{exp_date}/{name_file_laser}\", index_col=0)\n",
    "\n",
    "list_start_times, list_end_times = [], []\n",
    "\n",
    "\n",
    "# Modify dates\n",
    "for value_on, value_off in zip(df_laser['Turn ON Laser Time'].values, df_laser['Turn OFF Laser Time'].values):\n",
    "    value_on, value_off = value_on.replace(':', '.'), value_off.replace(':', '.')\n",
    "    tuple_on = (int(value_on.split('.')[0]), int(value_on.split('.')[1]), int(value_on.split('.')[2]), int(value_on.split('.')[3]))\n",
    "    tuple_off = (int(value_off.split('.')[0]), int(value_off.split('.')[1]), int(value_off.split('.')[2]), int(value_off.split('.')[3]))\n",
    "\n",
    "    list_start_times.append((dt.datetime.combine(hoy, dt.time(tuple_on[0], tuple_on[1], tuple_on[2], tuple_on[3]))  - time_absolute_start).total_seconds() + time_window_seconds)\n",
    "    list_end_times.append((dt.datetime.combine(hoy, dt.time(tuple_off[0], tuple_off[1], tuple_off[2], tuple_off[3]))  - time_absolute_start).total_seconds() + time_window_seconds)\n",
    "\n",
    "\n",
    "df_laser['start_times'], df_laser['end_times'] = list_start_times, list_end_times\n",
    "df_laser['duration'] = df_laser['ON duration (ms)'] / 1000\n",
    "df_laser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voltages = sorted(set(df_laser['Laser Power (mW)'].values))\n",
    "electrodes = sorted(set(df_spikes_filter['electrode_str'].values))\n",
    "\n",
    "window = 2\n",
    "\n",
    "fig, axs = plt.subplots(len(voltages), 1, figsize=(18, 25))\n",
    "\n",
    "\n",
    "for idx, voltage in enumerate(voltages):\n",
    "    df_laser_sub = df_laser[df_laser['Laser Power (mW)'] == voltage]\n",
    "    t_0, t_f = min(df_laser_sub['start_times']), max(df_laser_sub['end_times'])\n",
    "\n",
    "\n",
    "    for rep, start, end in zip(df_laser_sub['Repetition'].values, df_laser_sub['start_times'].values, df_laser_sub['end_times'].values):\n",
    "        axs[idx].add_patch(mpl.patches.Rectangle((start, -1), end - start, len(electrodes)+1, alpha=0.25, color='#800000'))\n",
    "\n",
    "    for electrode_idx, electrode in enumerate(electrodes):\n",
    "        df_spikes_sub = df_spikes_filter[(df_spikes_filter['Time (s)'] > t_0 - window) & (df_spikes_filter['Time (s)'] < t_f + window) & (df_spikes_filter['electrode_str'] == electrode)]\n",
    "        axs[idx].scatter(x=df_spikes_sub['Time (s)'].values, y=[electrode_idx] * len(df_spikes_sub), marker='|', s=100, c='#7f7f7f')\n",
    "    \n",
    "\n",
    "\n",
    "    axs[idx].set_yticks(np.array(range(len(electrodes))))\n",
    "    axs[idx].set_yticklabels(electrodes)\n",
    "    axs[idx].set_ylim([-1, len(electrodes)])\n",
    "    axs[idx].set_xlim([t_0 - window, t_f+window])\n",
    "    axs[idx].tick_params(left = False)\n",
    "    axs[idx].set_xlabel('Time (s)')\n",
    "    axs[idx].set_ylabel('Electrodes')\n",
    "\n",
    "    axs[0].title.set_text('0 mW')\n",
    "    axs[1].title.set_text('20 mW')\n",
    "    axs[2].title.set_text('40 mW')\n",
    "    axs[3].title.set_text('60 mW')\n",
    "    axs[4].title.set_text('80 mW')\n",
    "    axs[5].title.set_text('100 mW')\n",
    "\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=0.9,\n",
    "                    wspace=0.4,\n",
    "                    hspace=0.4)\n",
    "\n",
    "\n",
    "plt.savefig(f'{RESULTS_FOLDER}/{exp_date}/{column_time}/{name_sample}_spikeplot.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the mean representation time between pulses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = 0.1\n",
    "cutoff_counts = 60\n",
    "\n",
    "time_ranges = np.arange(np.min(df_laser['start_times']) , np.max(df_laser['end_times']) , tw)\n",
    "time_ranges_mean = (time_ranges[1:] + time_ranges[:-1]) * 0.5 \n",
    "\n",
    "counts = np.array([len(df_spikes_filter[(df_spikes_filter['Time (s)'] >= start) & (df_spikes_filter['Time (s)'] < end)]) for start, end in zip(time_ranges[:-1], time_ranges[1: ])])\n",
    "len(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,5))\n",
    "tmps = np.argwhere(counts > cutoff_counts).flatten() * tw\n",
    "diff = tmps[1: ] - tmps[: -1]\n",
    "sns.violinplot(diff[diff > 3 * tw])\n",
    "plt.xlabel(name_sample)\n",
    "plt.ylabel('Time between bursts')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{RESULTS_FOLDER}/{exp_date}/{column_time}/{name_sample}_distribution_interspike_gap_duration.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the mean firing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_voltages_MFR, list_electrodes_MFR, list_MFR = [], [], []\n",
    "\n",
    "\n",
    "for idx_vol, voltage in enumerate(voltages):\n",
    "    for idx_elec, electrode in enumerate(electrodes):\n",
    "        df_laser_sub = df_laser[df_laser['Laser Power (mW)'] == voltage]\n",
    "        t_0, t_f = min(df_laser_sub['start_times']), max(df_laser_sub['end_times'])\n",
    "        \n",
    "\n",
    "        df_spikes_sub = df_spikes_filter[(df_spikes_filter['electrode_str'] == electrode) & (df_spikes_filter['Time (s)'] > t_0) & (df_spikes_filter['Time (s)'] < t_f)]\n",
    "        MFR = len(df_spikes_sub) / (t_f - t_0)\n",
    "        list_MFR.append(MFR)\n",
    "        list_voltages_MFR.append(voltage)\n",
    "        list_electrodes_MFR.append(electrode)\n",
    "\n",
    "df_MFR = pd.DataFrame({'voltage': list_voltages_MFR, 'electrode': list_electrodes_MFR, 'MFR': list_MFR})\n",
    "\n",
    "df_MFR.to_csv(f'{RESULTS_FOLDER}/{exp_date}/{column_time}/{name_sample}_MRF_raw.csv', sep=';', index=None)\n",
    "df_MFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MRF_pivot = df_MFR.pivot(index='electrode', columns='voltage', values='MFR')\n",
    "\n",
    "df_MRF_pivot.to_csv(f'{RESULTS_FOLDER}/{exp_date}/{column_time}/{name_sample}_MRF_pivot.csv', sep=';')\n",
    "df_MRF_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MRF_pivot_norm = df_MRF_pivot.copy()\n",
    "for voltage in voltages[1:]:\n",
    "    df_MRF_pivot_norm[voltage] /= df_MRF_pivot_norm[voltages[0]]\n",
    "\n",
    "df_MRF_pivot_norm = df_MRF_pivot_norm.iloc[:, 1:] * 100\n",
    "\n",
    "df_MRF_pivot_norm.to_csv(f'{RESULTS_FOLDER}/{exp_date}/{column_time}/{name_sample}_MRF_pivot_norm.csv', sep=';')\n",
    "df_MRF_pivot_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MFR['MFR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_MFR.groupby('voltage')\n",
    "\n",
    "df_MFR_summary = pd.DataFrame({'voltage': voltages, \n",
    "                               'sum': grouped[['MFR']].sum()['MFR'].values, \n",
    "                               'mean': grouped[['MFR']].mean()['MFR'].values, \n",
    "                               'median': grouped[['MFR']].median()['MFR'].values, \n",
    "                               'std': grouped[['MFR']].std()['MFR'].values})\n",
    "\n",
    "df_MFR_summary.to_csv(f'{RESULTS_FOLDER}/{exp_date}/{column_time}/{name_sample}_MRF_summary.csv', sep=';', index=None)\n",
    "df_MFR_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoneuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
